{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NH-Davis/IBM-AI-Engineer-Intro-to-Deep-Learning/blob/main/DL0321EN_3_1_Pretrained_Models_py_v1_0_complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66f07cc3-f171-4267-aee6-ce7752933b77"
      },
      "source": [
        "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/image/IDSN-logo.png\" width=\"400\"> </a>\n",
        "\n",
        "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e331f40b-337d-4c41-9371-04596800ad74"
      },
      "source": [
        "## Objective\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48dc60a8-2320-435c-90e1-f7b44c170728"
      },
      "source": [
        "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac02d0d3-1136-426e-8294-0d7d9d505786"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "    \n",
        "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
        "2. <a href=\"#item32\">Download Data</a>  \n",
        "3. <a href=\"#item33\">Define Global Constants</a>  \n",
        "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
        "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
        "\n",
        "</font>\n",
        "    \n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a39a4dc-1c2c-4bf1-bedb-eac3969c838a"
      },
      "source": [
        "   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5444ae91-6e40-4287-a194-bcb2d269ed50"
      },
      "source": [
        "<a id='item31'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9008da8d-7cb4-4333-925d-9937c5a83ab6"
      },
      "source": [
        "## Import Libraries and Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w8Qi0-mfaCM",
        "outputId": "138af676-0cd0-4741-e4e7-f65b429e6b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting skillsnetwork\n",
            "  Downloading skillsnetwork-0.21.9-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (7.34.0)\n",
            "Collecting ipywidgets<9,>=8 (from skillsnetwork)\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5,>=4 in /usr/local/lib/python3.10/dist-packages (from skillsnetwork) (4.66.2)\n",
            "Collecting comm>=0.1.3 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.10 (from ipywidgets<9,>=8->skillsnetwork)\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab-widgets~=3.0.10 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=8->skillsnetwork) (3.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->skillsnetwork)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->skillsnetwork) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->skillsnetwork) (2024.2.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->skillsnetwork) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->skillsnetwork) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->skillsnetwork) (0.2.13)\n",
            "Installing collected packages: widgetsnbextension, jedi, comm, ipywidgets, skillsnetwork\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.2 jedi-0.19.1 skillsnetwork-0.21.9 widgetsnbextension-4.0.10\n"
          ]
        }
      ],
      "source": [
        "!pip install skillsnetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0ff4a4c-47c2-4372-8c59-2cfda80d64e7"
      },
      "source": [
        "Let's start the lab by importing the libraries that we will be using in this lab. First we will need the library that helps us to import the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2cc2be08-b540-4918-b1a9-a2df287ff4d9"
      },
      "outputs": [],
      "source": [
        "import skillsnetwork"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a683d5c-10fd-4e9b-9fe7-3cd2c8928099"
      },
      "source": [
        "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "675684c0-2392-4487-953a-99b049b0450c"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "683598d4-99e2-42b0-991e-00a3e5fd5d99"
      },
      "source": [
        "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "58f57fd4-ffb5-4fd7-a67c-0cf73a1cacde"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ecf765d-36f8-4262-b631-cb0f60a217d9"
      },
      "source": [
        "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f96d6994-63e4-4297-b98a-0c2ab2439cd0"
      },
      "outputs": [],
      "source": [
        "from keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53d76782-0cd7-4ced-8a37-096675e632d3"
      },
      "source": [
        "<a id='item32'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e55f048-ce67-455a-9e3a-dc5cc0ded766"
      },
      "source": [
        "## Download Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89eae3c7-10fc-4e55-a043-b544dd7776f4"
      },
      "source": [
        "In this section, you are going to download the data from IBM object storage using **skillsnetwork.prepare** command. skillsnetwork.prepare is a command that's used to download a zip file, unzip it and store it in a specified directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "57f426c8ce894696a14a34a69ec6cea6",
            "511fc9c1f56a4887b5c8106e91d2a0c5",
            "6640ff06f6b24c7faa744bcef5366b1c",
            "5c55723028fa411792de01c644a230de",
            "a19a81a320cc496690bf9c2c4d74b06f",
            "c67a93ba974243ccb5342ee48db06c1a",
            "49606e1073b44d0f8188670e6f8a7b0a",
            "20864d32f1bf49188e4f62753aaf25fe",
            "0b570677bfbc4cf4b6c3fe47f74cc45d",
            "1158e26c0cd34bdcbe15412714b29351",
            "598e6985f9394440a000c915d23e383a",
            "c64fdac810a9496c823b7032fe9324b6",
            "a04ceccae3da4c398eefa13c42418a9e",
            "658a5b54b4ab4617892e72af6e8b20a9",
            "a5b98749f96548e3ac670d47ef5dd49a",
            "250574123bdc45b88c93895a0a90d9af",
            "cdcb4e138c884c3494e09da779eca937",
            "6d7302b2dbba404d9bfc46329c9ee074",
            "e3cfe4a39dc047f49005310fb7dd1a06",
            "956ab7f3fe204a62a396c64fb5c99443",
            "4679801a2f78467e8e504ed7ca632b4a",
            "f1df9aad5ef44f69a202e7454e070212"
          ]
        },
        "id": "24ee9fe4-8e25-45a5-b56b-61c51b69bbb5",
        "outputId": "80aff2dd-dcfe-42ef-aef2-68ee936be741"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading concrete_data_week3.zip:   0%|          | 0/97863179 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57f426c8ce894696a14a34a69ec6cea6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30036 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c64fdac810a9496c823b7032fe9324b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to '.'\n"
          ]
        }
      ],
      "source": [
        "## get the data\n",
        "await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0321EN-SkillsNetwork/concrete_data_week3.zip\", overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "WWEhVeYm_X0A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "PdJ_yvlL_X0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "AyPQYMFw_X0L"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "K9tCcntefoB4"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeIVDFTNfoB4"
      },
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dVaH-tt0foB4"
      },
      "outputs": [],
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1926133-f936-42c7-8cec-7e5ebcbb20b9"
      },
      "source": [
        "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d1c1123-f5b8-4270-aa89-27c71ca7d4a9"
      },
      "source": [
        "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50** error. So please **DO NOT DO IT**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddd1dd78-ec92-4710-8cdf-47091a74a872"
      },
      "source": [
        "<a id='item33'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "877483a0-cb76-4928-a36a-39785cf04808"
      },
      "source": [
        "## Define Global Constants\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b192844f-8ebf-485b-b97d-e525515fa5d2"
      },
      "source": [
        "Here, we will define constants that we will be using throughout the rest of the lab.\n",
        "\n",
        "1. We are obviously dealing with two classes, so *num_classes* is 2.\n",
        "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
        "3. We will training and validating the model using batches of 100 images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "b5f7cace-b3c4-4e58-9c0d-5b52f3357713"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "\n",
        "image_resize = 224\n",
        "\n",
        "batch_size_training = 100\n",
        "batch_size_validation = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0183cdad-017f-41ea-ac37-d979b398ad16"
      },
      "source": [
        "<a id='item34'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cac7d34d-9a92-44de-8245-d22202b73b3a"
      },
      "source": [
        "## Construct ImageDataGenerator Instances\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd27dd04-a55f-4c99-9259-0b2c3d296090"
      },
      "source": [
        "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "db7834eb-a1e4-4a4b-a075-29900939bdc4"
      },
      "outputs": [],
      "source": [
        "data_generator = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b487ed3-ae96-4b96-8038-7e5cda19b36c"
      },
      "source": [
        "Next, we will use the *flow_from_directory* method to get the training images as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "595ecbe2-bfdc-4523-9acd-3706181796b8",
        "outputId": "a5996817-2b6d-4902-a410-3206bb69eccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10001 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/train',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_training,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e1f3fd-c370-4b6a-a178-2299a39880cb"
      },
      "source": [
        "**Note**: in this lab, we will be using the full data-set of 40,000 images for training and validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "160bbbd7-035b-4c35-b870-556433bcd577"
      },
      "source": [
        "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc0f0817-76c4-4467-a062-c0c302658371",
        "outputId": "4e3e3416-9554-4fc6-9e16-21d1e1494d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5001 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "## Type your answer here\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60a0dc3d-3401-4b13-8237-fef3435998a7"
      },
      "source": [
        "Double-click __here__ for the solution.\n",
        "<!-- The correct answer is:\n",
        "validation_generator = data_generator.flow_from_directory(\n",
        "    'concrete_data_week3/valid',\n",
        "    target_size=(image_resize, image_resize),\n",
        "    batch_size=batch_size_validation,\n",
        "    class_mode='categorical')\n",
        "-->\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cefbac4-f731-44a4-b928-c53b635b687f"
      },
      "source": [
        "<a id='item35'></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1e87236-bfd3-4ff8-942d-133ebd71d2d2"
      },
      "source": [
        "## Build, Compile and Fit Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f398574-9232-4051-8463-663fe90a2f47"
      },
      "source": [
        "In this section, we will start building our model. We will use the Sequential model class from Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "324b72dc-2a07-48a6-a4e7-b91de8338dcd"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f9ce8f4-3052-478f-92e0-412574a9ffba"
      },
      "source": [
        "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f75d767-8ca1-4cea-b11f-e8c73909ef35",
        "outputId": "5a93f8df-7b17-41db-e839-e29f32a30c71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model.add(ResNet50(\n",
        "    include_top=False,\n",
        "    pooling='avg',\n",
        "    weights='imagenet',\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fa6e617-2400-470a-aad9-416bdc45f07b"
      },
      "source": [
        "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "517f94df-1874-457c-84e6-e1dba49f86e0"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(num_classes, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd8b80d-795d-41cc-897f-d942bb8ceaa5"
      },
      "source": [
        "You can access the model's layers using the *layers* attribute of our model object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c3e20f7-ccd7-42aa-8a95-5bd0e5361899",
        "outputId": "4685f8ec-d773-4181-9f62-efeb0ac096b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.engine.functional.Functional at 0x79792dd79f60>,\n",
              " <keras.src.layers.core.dense.Dense at 0x79792ec52740>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ead62664-0389-4b64-a87b-31054cae45f1"
      },
      "source": [
        "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfb56e7f-9153-4ecb-a22f-34e4a82c3a1e"
      },
      "source": [
        "You can access the ResNet50 layers by running the following:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3adb56a8-130d-4e65-8f77-f015cf759afa",
        "outputId": "ec135303-1edc-4110-baaf-3aa406733fc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.src.engine.input_layer.InputLayer at 0x797953a58b20>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x79792ec52ad0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953a593f0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953a59870>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953a5a980>,\n",
              " <keras.src.layers.reshaping.zero_padding2d.ZeroPadding2D at 0x797953a5b070>,\n",
              " <keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x79795376c250>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795376d300>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795376d180>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79795376fdf0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795376d000>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795376fa60>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79795378dcc0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795376cd90>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795378c220>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953a5b490>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795378e4a0>,\n",
              " <keras.src.layers.merging.add.Add at 0x79795378f490>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79795378d6f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795378e1a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537a12d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79795378f850>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795378f6a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795378d7e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953a5a0b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795376c160>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795378d750>,\n",
              " <keras.src.layers.merging.add.Add at 0x79795376c580>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537b52d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537b61a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537a32b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537b7580>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537b40d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537b7760>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537b6f20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537d5390>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537d5ab0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7979537b7880>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537d7940>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537d4430>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537e5c60>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537e7340>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537e77f0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537e6590>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537f8a60>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537d56c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537f9f60>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537e4f70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537fa0e0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7979537fac80>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537fbdf0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953820580>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953820880>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979538222f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979538227a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953820160>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979538224a0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953821990>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537e5d50>,\n",
              " <keras.src.layers.merging.add.Add at 0x7979537e5fc0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537f98d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x7979537b4c40>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979537d7610>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979537d7730>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953835420>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953836050>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953837460>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953837910>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953834880>,\n",
              " <keras.src.layers.merging.add.Add at 0x797953837370>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953841b10>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953840eb0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979538424d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953843f40>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953841f30>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x797953842c20>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953859d20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x797953858a90>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79795385a500>,\n",
              " <keras.src.layers.merging.add.Add at 0x79795385b4f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x797953859750>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de661a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de65ff0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de65ea0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de67610>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de78310>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de66590>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79795385b340>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de66440>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de64e80>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de653f0>,\n",
              " <keras.src.layers.merging.add.Add at 0x7979538375b0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x7979538351e0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de65420>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de78430>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de7b940>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de7b640>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de7bd60>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de91870>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de905b0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de920e0>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792de930d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de93be0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de90820>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792de91c30>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792dea1de0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792dea22c0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dea29e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792dea3a30>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792dea06d0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792deb8280>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792dea30a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792debaa70>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792debb190>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792debb760>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792debbee0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792ded8e80>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792ded9000>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792ded99f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792ded8640>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dedafe0>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792deda110>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792dee85b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792ded86a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792deda2c0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792de91690>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de797e0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792deb8790>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792debb580>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792de78070>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dee9030>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792de7a140>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df042b0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df04940>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df051e0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df06c50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df07100>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df07fd0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df07760>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df100a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df10f40>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792df12200>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df10670>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df109a0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df28d30>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df281f0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df2ae60>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x7979538436a0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df2be20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df13b50>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df2aa70>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df13cd0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df2be50>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792df28280>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df46860>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df46c80>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df47250>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df47b20>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df46ec0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df290f0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df28460>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df10490>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dea2080>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792de933d0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df107c0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792df10a00>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792df04ca0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792df10dc0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792dd68dc0>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dd6af20>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792dd6a7d0>,\n",
              " <keras.src.layers.convolutional.conv2d.Conv2D at 0x79792dd6a320>,\n",
              " <keras.src.layers.normalization.batch_normalization.BatchNormalization at 0x79792dd68ac0>,\n",
              " <keras.src.layers.merging.add.Add at 0x79792dd68ca0>,\n",
              " <keras.src.layers.core.activation.Activation at 0x79792dd781c0>,\n",
              " <keras.src.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x79792dd6b400>]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "model.layers[0].layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcc55835-9b6a-4270-a922-ffc842a3b2f7"
      },
      "source": [
        "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ba503665-a9ca-456c-8a6a-072767030476"
      },
      "outputs": [],
      "source": [
        "model.layers[0].trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb8c4bc5-43b0-41af-84b8-c3f44700a241"
      },
      "source": [
        "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25b95f54-b4f5-4ff5-b9f7-59bd877fc6f2",
        "outputId": "acef53cb-214e-41cb-ca6a-c60c56cc8aee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23591810 (90.00 MB)\n",
            "Trainable params: 4098 (16.01 KB)\n",
            "Non-trainable params: 23587712 (89.98 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d174115c-5697-4575-a241-c2d6a67b25cf"
      },
      "source": [
        "Next we compile our model using the **adam** optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e28af4b7-b584-47d9-a996-f6e1c880e2cf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eb49523-42bf-43ec-9932-122c88162abf"
      },
      "source": [
        "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bb075ee5-15d6-4e6c-83e1-8bc4b9c9b927"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch_training = len(train_generator)\n",
        "steps_per_epoch_validation = len(validation_generator)\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e940f178-9402-4b49-a92d-5d49c5ce2d84"
      },
      "source": [
        "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2a03e7-2a37-424c-ade0-fb9030bd4fa6",
        "outputId": "ebe4b6a5-0f97-4e1d-8bfc-0adefd5d0aa6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-172e67583a70>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  fit_history = model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "101/101 [==============================] - 3007s 30s/step - loss: 0.0853 - accuracy: 0.9616 - val_loss: 0.0210 - val_accuracy: 0.9942\n",
            "Epoch 2/2\n",
            "101/101 [==============================] - 3024s 30s/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0135 - val_accuracy: 0.9956\n"
          ]
        }
      ],
      "source": [
        "fit_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=steps_per_epoch_training,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=steps_per_epoch_validation,\n",
        "    verbose=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5ecefc5-ddd9-4a55-82e0-c2d85da6cfb6"
      },
      "source": [
        "Now that the model is trained, you are ready to start using it to classify images.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "219a8c0f-7272-4344-86b1-b48a94bf8d06"
      },
      "source": [
        "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6886e4e0-12c1-4f92-9131-bb65e9448da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e210b3e-e585-4884-8543-b131810426b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('classifier_resnet_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5811996e-a9d9-4f55-b217-91b706c2b540"
      },
      "source": [
        "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1532efc6-f5b6-4436-8ffb-87e3ce4e2759"
      },
      "source": [
        "### Thank you for completing this lab!\n",
        "\n",
        "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45157c39-1105-452b-bbf4-b2b9a072bbf4"
      },
      "source": [
        "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c602219-d860-4c13-8d58-3b09e597c467"
      },
      "source": [
        "\n",
        "## Change Log\n",
        "\n",
        "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
        "|---|---|---|---|\n",
        "| 2020-09-18  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n",
        "| 2023-01-03  | 3.0  | Artem |  Updated the file import section|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c4e8fd7-5aac-4264-a473-c6b80ac193b9"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "57f426c8ce894696a14a34a69ec6cea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_511fc9c1f56a4887b5c8106e91d2a0c5",
              "IPY_MODEL_6640ff06f6b24c7faa744bcef5366b1c",
              "IPY_MODEL_5c55723028fa411792de01c644a230de"
            ],
            "layout": "IPY_MODEL_a19a81a320cc496690bf9c2c4d74b06f",
            "tabbable": null,
            "tooltip": null
          }
        },
        "511fc9c1f56a4887b5c8106e91d2a0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c67a93ba974243ccb5342ee48db06c1a",
            "placeholder": "​",
            "style": "IPY_MODEL_49606e1073b44d0f8188670e6f8a7b0a",
            "tabbable": null,
            "tooltip": null,
            "value": "Downloading concrete_data_week3.zip: 100%"
          }
        },
        "6640ff06f6b24c7faa744bcef5366b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_20864d32f1bf49188e4f62753aaf25fe",
            "max": 97863179,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b570677bfbc4cf4b6c3fe47f74cc45d",
            "tabbable": null,
            "tooltip": null,
            "value": 97863179
          }
        },
        "5c55723028fa411792de01c644a230de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1158e26c0cd34bdcbe15412714b29351",
            "placeholder": "​",
            "style": "IPY_MODEL_598e6985f9394440a000c915d23e383a",
            "tabbable": null,
            "tooltip": null,
            "value": " 97863179/97863179 [00:02&lt;00:00, 40241122.23it/s]"
          }
        },
        "a19a81a320cc496690bf9c2c4d74b06f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67a93ba974243ccb5342ee48db06c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49606e1073b44d0f8188670e6f8a7b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "20864d32f1bf49188e4f62753aaf25fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b570677bfbc4cf4b6c3fe47f74cc45d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1158e26c0cd34bdcbe15412714b29351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "598e6985f9394440a000c915d23e383a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c64fdac810a9496c823b7032fe9324b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a04ceccae3da4c398eefa13c42418a9e",
              "IPY_MODEL_658a5b54b4ab4617892e72af6e8b20a9",
              "IPY_MODEL_a5b98749f96548e3ac670d47ef5dd49a"
            ],
            "layout": "IPY_MODEL_250574123bdc45b88c93895a0a90d9af",
            "tabbable": null,
            "tooltip": null
          }
        },
        "a04ceccae3da4c398eefa13c42418a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_cdcb4e138c884c3494e09da779eca937",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7302b2dbba404d9bfc46329c9ee074",
            "tabbable": null,
            "tooltip": null,
            "value": "Extracting concrete_data_week3.zip: 100%"
          }
        },
        "658a5b54b4ab4617892e72af6e8b20a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_e3cfe4a39dc047f49005310fb7dd1a06",
            "max": 30036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_956ab7f3fe204a62a396c64fb5c99443",
            "tabbable": null,
            "tooltip": null,
            "value": 30036
          }
        },
        "a5b98749f96548e3ac670d47ef5dd49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_4679801a2f78467e8e504ed7ca632b4a",
            "placeholder": "​",
            "style": "IPY_MODEL_f1df9aad5ef44f69a202e7454e070212",
            "tabbable": null,
            "tooltip": null,
            "value": " 30036/30036 [00:07&lt;00:00, 5048.58it/s]"
          }
        },
        "250574123bdc45b88c93895a0a90d9af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdcb4e138c884c3494e09da779eca937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7302b2dbba404d9bfc46329c9ee074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "e3cfe4a39dc047f49005310fb7dd1a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956ab7f3fe204a62a396c64fb5c99443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4679801a2f78467e8e504ed7ca632b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1df9aad5ef44f69a202e7454e070212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}